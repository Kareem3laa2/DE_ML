{"timestamp":"2025-07-03T19:14:49.236523","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-03T19:14:49.236974","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/telco_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-03T19:14:49.260587","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:49.261197","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec spark-master /spark/bin/spark-submit /opt/spark-apps/get_clean.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:49.270849","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:50.717266","level":"info","event":"25/07/03 19:14:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.252196","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.260844","level":"info","event":"25/07/03 19:14:51 INFO SparkContext: Running Spark version 3.1.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.294642","level":"info","event":"25/07/03 19:14:51 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.294865","level":"info","event":"25/07/03 19:14:51 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.294961","level":"info","event":"25/07/03 19:14:51 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.295144","level":"info","event":"25/07/03 19:14:51 INFO SparkContext: Submitted application: TelcoExploration","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.315642","level":"info","event":"25/07/03 19:14:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.328509","level":"info","event":"25/07/03 19:14:51 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.328763","level":"info","event":"25/07/03 19:14:51 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.372251","level":"info","event":"25/07/03 19:14:51 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.372627","level":"info","event":"25/07/03 19:14:51 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.372748","level":"info","event":"25/07/03 19:14:51 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.372859","level":"info","event":"25/07/03 19:14:51 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.372949","level":"info","event":"25/07/03 19:14:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.555744","level":"info","event":"25/07/03 19:14:51 INFO Utils: Successfully started service 'sparkDriver' on port 36739.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.581398","level":"info","event":"25/07/03 19:14:51 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.606588","level":"info","event":"25/07/03 19:14:51 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.626122","level":"info","event":"25/07/03 19:14:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.626884","level":"info","event":"25/07/03 19:14:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.631241","level":"info","event":"25/07/03 19:14:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.644357","level":"info","event":"25/07/03 19:14:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1ab1621d-509c-4ff2-9628-1a2c85249deb","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.665271","level":"info","event":"25/07/03 19:14:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.682061","level":"info","event":"25/07/03 19:14:51 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.879991","level":"info","event":"25/07/03 19:14:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:51.936702","level":"info","event":"25/07/03 19:14:51 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://a5088bcdb211:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.129084","level":"info","event":"25/07/03 19:14:52 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.182415","level":"info","event":"25/07/03 19:14:52 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.5:7077 after 33 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.301167","level":"info","event":"25/07/03 19:14:52 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250703191452-0000","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.309243","level":"info","event":"25/07/03 19:14:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46429.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.309817","level":"info","event":"25/07/03 19:14:52 INFO NettyBlockTransferService: Server created on a5088bcdb211:46429","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.309956","level":"info","event":"25/07/03 19:14:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.319021","level":"info","event":"25/07/03 19:14:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a5088bcdb211, 46429, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.323183","level":"info","event":"25/07/03 19:14:52 INFO BlockManagerMasterEndpoint: Registering block manager a5088bcdb211:46429 with 366.3 MiB RAM, BlockManagerId(driver, a5088bcdb211, 46429, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.326050","level":"info","event":"25/07/03 19:14:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a5088bcdb211, 46429, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.327462","level":"info","event":"25/07/03 19:14:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a5088bcdb211, 46429, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.340106","level":"info","event":"25/07/03 19:14:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250703191452-0000/0 on worker-20250703191434-172.21.0.6-37241 (172.21.0.6:37241) with 12 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.341211","level":"info","event":"25/07/03 19:14:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20250703191452-0000/0 on hostPort 172.21.0.6:37241 with 12 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.462538","level":"info","event":"25/07/03 19:14:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250703191452-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.507535","level":"info","event":"25/07/03 19:14:52 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.782425","level":"info","event":"25/07/03 19:14:52 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/spark-warehouse').","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:52.782584","level":"info","event":"25/07/03 19:14:52 INFO SharedState: Warehouse path is 'file:/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:54.202606","level":"info","event":"25/07/03 19:14:54 INFO InMemoryFileIndex: It took 76 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:54.261748","level":"info","event":"25/07/03 19:14:54 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:54.528122","level":"info","event":"25/07/03 19:14:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.6:56998) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:54.635021","level":"info","event":"25/07/03 19:14:54 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.6:39339 with 366.3 MiB RAM, BlockManagerId(0, 172.21.0.6, 39339, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.010361","level":"info","event":"25/07/03 19:14:56 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.014026","level":"info","event":"25/07/03 19:14:56 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.018049","level":"info","event":"25/07/03 19:14:56 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.701462","level":"info","event":"25/07/03 19:14:56 INFO CodeGenerator: Code generated in 244.166245 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.749922","level":"info","event":"25/07/03 19:14:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 303.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.796704","level":"info","event":"25/07/03 19:14:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.799107","level":"info","event":"25/07/03 19:14:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on a5088bcdb211:46429 (size: 27.5 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.801681","level":"info","event":"25/07/03 19:14:56 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.810413","level":"info","event":"25/07/03 19:14:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.909546","level":"info","event":"25/07/03 19:14:56 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.923262","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.923403","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.923459","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.924562","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.928455","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.978819","level":"info","event":"25/07/03 19:14:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.980931","level":"info","event":"25/07/03 19:14:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.981259","level":"info","event":"25/07/03 19:14:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on a5088bcdb211:46429 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.981710","level":"info","event":"25/07/03 19:14:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.993354","level":"info","event":"25/07/03 19:14:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:56.993872","level":"info","event":"25/07/03 19:14:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:57.033987","level":"info","event":"25/07/03 19:14:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:57.277074","level":"info","event":"25/07/03 19:14:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.6:39339 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:58.153513","level":"info","event":"25/07/03 19:14:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.6:39339 (size: 27.5 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.048348","level":"info","event":"25/07/03 19:14:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2027 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.050335","level":"info","event":"25/07/03 19:14:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.056643","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 2.114 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.059856","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.060004","level":"info","event":"25/07/03 19:14:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.062849","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 2.152998 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.086263","level":"info","event":"25/07/03 19:14:59 INFO CodeGenerator: Code generated in 12.589404 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.137203","level":"info","event":"25/07/03 19:14:59 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.137379","level":"info","event":"25/07/03 19:14:59 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.137446","level":"info","event":"25/07/03 19:14:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.143831","level":"info","event":"25/07/03 19:14:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 303.8 KiB, free 365.7 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.172227","level":"info","event":"25/07/03 19:14:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.173006","level":"info","event":"25/07/03 19:14:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on a5088bcdb211:46429 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.173848","level":"info","event":"25/07/03 19:14:59 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.175432","level":"info","event":"25/07/03 19:14:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.224257","level":"info","event":"25/07/03 19:14:59 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.225927","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.226073","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.226138","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.226188","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.227101","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.250347","level":"info","event":"25/07/03 19:14:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.8 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.252338","level":"info","event":"25/07/03 19:14:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.252831","level":"info","event":"25/07/03 19:14:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on a5088bcdb211:46429 (size: 8.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.253606","level":"info","event":"25/07/03 19:14:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.254539","level":"info","event":"25/07/03 19:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.254698","level":"info","event":"25/07/03 19:14:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.256209","level":"info","event":"25/07/03 19:14:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:14:59.275945","level":"info","event":"25/07/03 19:14:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.6:39339 (size: 8.0 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.424034","level":"info","event":"25/07/03 19:15:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.6:39339 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.667732","level":"info","event":"25/07/03 19:15:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1411 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.667935","level":"info","event":"25/07/03 19:15:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.668509","level":"info","event":"25/07/03 19:15:00 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 1.440 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.668607","level":"info","event":"25/07/03 19:15:00 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.668672","level":"info","event":"25/07/03 19:15:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:00.670277","level":"info","event":"25/07/03 19:15:00 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 1.446183 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.226507","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.226635","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.226695","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.263608","level":"info","event":"25/07/03 19:15:01 INFO CodeGenerator: Code generated in 16.212695 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.268106","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 303.7 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.276622","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.277485","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on a5088bcdb211:46429 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.277977","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Created broadcast 4 from approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.281209","level":"info","event":"25/07/03 19:15:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.301671","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Starting job: approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.302540","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Got job 2 (approxQuantile at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.302642","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Final stage: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.302685","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.302861","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.303576","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.318356","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 20.1 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.321662","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.322448","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on a5088bcdb211:46429 (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.322934","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.323550","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.323657","level":"info","event":"25/07/03 19:15:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.325124","level":"info","event":"25/07/03 19:15:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.337156","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.6:39339 (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.451492","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.6:39339 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.638193","level":"info","event":"25/07/03 19:15:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 312 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.638388","level":"info","event":"25/07/03 19:15:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.638876","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0) finished in 0.334 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.638971","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.639783","level":"info","event":"25/07/03 19:15:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.641319","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Job 2 finished: approxQuantile at NativeMethodAccessorImpl.java:0, took 0.339523 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.772075","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.772897","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Post-Scan Filters: ((CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END < -3927.1499999999996) OR (CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END > 7662.049999999999))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.773173","level":"info","event":"25/07/03 19:15:01 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.830421","level":"info","event":"25/07/03 19:15:01 INFO CodeGenerator: Code generated in 15.342604 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.864221","level":"info","event":"25/07/03 19:15:01 INFO CodeGenerator: Code generated in 21.985368 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.867739","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 303.7 KiB, free 365.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.881058","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.881607","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on a5088bcdb211:46429 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.882567","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.883428","level":"info","event":"25/07/03 19:15:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.930169","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.932876","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.935161","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.935382","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.935463","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.936532","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.937793","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.947470","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 19.7 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.951873","level":"info","event":"25/07/03 19:15:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.953031","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on a5088bcdb211:46429 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.953372","level":"info","event":"25/07/03 19:15:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.955148","level":"info","event":"25/07/03 19:15:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.955248","level":"info","event":"25/07/03 19:15:01 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.957602","level":"info","event":"25/07/03 19:15:01 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.6, executor 0, partition 0, ANY, 4865 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:01.973004","level":"info","event":"25/07/03 19:15:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.6:39339 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.057052","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.6:39339 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.165974","level":"info","event":"25/07/03 19:15:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 206 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.166159","level":"info","event":"25/07/03 19:15:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.170604","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.226 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.170802","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.170892","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.170958","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: waiting: Set(ResultStage 4)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.171723","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.180889","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.193145","level":"info","event":"25/07/03 19:15:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.199931","level":"info","event":"25/07/03 19:15:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.200866","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on a5088bcdb211:46429 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.201350","level":"info","event":"25/07/03 19:15:02 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.202399","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.202550","level":"info","event":"25/07/03 19:15:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.207255","level":"info","event":"25/07/03 19:15:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.21.0.6, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.226533","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.6:39339 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.246598","level":"info","event":"25/07/03 19:15:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.6:56998","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.342034","level":"info","event":"25/07/03 19:15:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 137 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.342346","level":"info","event":"25/07/03 19:15:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.342791","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.153 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.342891","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.342953","level":"info","event":"25/07/03 19:15:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.343161","level":"info","event":"25/07/03 19:15:02 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.413188 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.346573","level":"info","event":"Number of outliers in totalcharges: 154","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.397719","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on a5088bcdb211:46429 in memory (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.402023","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.21.0.6:39339 in memory (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.421714","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on a5088bcdb211:46429 in memory (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.421907","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.21.0.6:39339 in memory (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.430049","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on a5088bcdb211:46429 in memory (size: 5.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.433616","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.21.0.6:39339 in memory (size: 5.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.446427","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_8_piece0 on a5088bcdb211:46429 in memory (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.450324","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.6:39339 in memory (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.459190","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on a5088bcdb211:46429 in memory (size: 8.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.461394","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.21.0.6:39339 in memory (size: 8.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.468483","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_5_piece0 on a5088bcdb211:46429 in memory (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.471790","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.21.0.6:39339 in memory (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.524413","level":"info","event":"25/07/03 19:15:02 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.524612","level":"info","event":"25/07/03 19:15:02 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.534722","level":"info","event":"25/07/03 19:15:02 INFO FileSourceStrategy: Output Data Schema: struct<customerID: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string ... 19 more fields>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.625612","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.625773","level":"info","event":"  File \"/opt/spark-apps/get_clean.py\", line 50, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.627601","level":"info","event":"    df_cleaned.write.mode(\"overwrite\").parquet(\"hdfs://namenode:8020/user/telco/cleaned/telco_cleaned.parquet\")","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.627785","level":"info","event":"  File \"/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1249, in parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.627869","level":"info","event":"  File \"/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.628070","level":"info","event":"  File \"/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 111, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.628163","level":"info","event":"  File \"/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671018","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o104.parquet.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671169","level":"info","event":": org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/telco/cleaned/telco_cleaned.parquet. Name node is in safe mode.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671220","level":"info","event":"The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:587c70d87296","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671267","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671294","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671321","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671353","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671377","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671400","level":"info","event":"\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671434","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671459","level":"info","event":"\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671486","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671520","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671543","level":"info","event":"\tat java.security.AccessController.doPrivileged(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671565","level":"info","event":"\tat javax.security.auth.Subject.doAs(Subject.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671593","level":"info","event":"\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671621","level":"info","event":"\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671644","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671673","level":"info","event":"\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671707","level":"info","event":"\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671730","level":"info","event":"\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671755","level":"info","event":"\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671787","level":"info","event":"\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671812","level":"info","event":"\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671868","level":"info","event":"\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671902","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671934","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671971","level":"info","event":"\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.671996","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672020","level":"info","event":"\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672043","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:236)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672067","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:130)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672091","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672114","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672141","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672164","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672186","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672208","level":"info","event":"\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672230","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672251","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672272","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672296","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672322","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672342","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672371","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672393","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672414","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672437","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672468","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672554","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672582","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672610","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672635","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672657","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672698","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672733","level":"info","event":"\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672760","level":"info","event":"\tat java.lang.reflect.Method.invoke(Method.java:498)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672789","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672812","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672835","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672861","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672884","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672916","level":"info","event":"\tat py4j.GatewayConnection.run(GatewayConnection.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672954","level":"info","event":"\tat java.lang.Thread.run(Thread.java:748)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.672995","level":"info","event":"Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/telco/cleaned/telco_cleaned.parquet. Name node is in safe mode.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673035","level":"info","event":"The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:587c70d87296","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673082","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673120","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673160","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673201","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673248","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673312","level":"info","event":"\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673362","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673401","level":"info","event":"\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673436","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673471","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673506","level":"info","event":"\tat java.security.AccessController.doPrivileged(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673543","level":"info","event":"\tat javax.security.auth.Subject.doAs(Subject.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673580","level":"info","event":"\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673618","level":"info","event":"\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673659","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673703","level":"info","event":"\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673749","level":"info","event":"\tat org.apache.hadoop.ipc.Client.call(Client.java:1457)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673781","level":"info","event":"\tat org.apache.hadoop.ipc.Client.call(Client.java:1367)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673804","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673850","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673888","level":"info","event":"\tat com.sun.proxy.$Proxy19.delete(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673925","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673951","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673975","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.673998","level":"info","event":"\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674023","level":"info","event":"\tat java.lang.reflect.Method.invoke(Method.java:498)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674049","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674095","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674119","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674183","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674220","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674245","level":"info","event":"\tat com.sun.proxy.$Proxy20.delete(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674274","level":"info","event":"\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674298","level":"info","event":"\t... 39 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.674324","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.692802","level":"info","event":"25/07/03 19:15:02 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.701100","level":"info","event":"25/07/03 19:15:02 INFO SparkUI: Stopped Spark web UI at http://a5088bcdb211:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.703982","level":"info","event":"25/07/03 19:15:02 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.704336","level":"info","event":"25/07/03 19:15:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.720123","level":"info","event":"25/07/03 19:15:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.736733","level":"info","event":"25/07/03 19:15:02 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.738524","level":"info","event":"25/07/03 19:15:02 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.744912","level":"info","event":"25/07/03 19:15:02 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.747395","level":"info","event":"25/07/03 19:15:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.757059","level":"info","event":"25/07/03 19:15:02 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.757256","level":"info","event":"25/07/03 19:15:02 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.757820","level":"info","event":"25/07/03 19:15:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-c223f6f2-96c4-457f-8d80-e086f4ead910","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.760533","level":"info","event":"25/07/03 19:15:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-191b2b19-ea73-47db-969a-107c379f037a","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.763582","level":"info","event":"25/07/03 19:15:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-c223f6f2-96c4-457f-8d80-e086f4ead910/pyspark-3d64ec3e-2c10-41a2-93cf-e03d016e317f","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.920078","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T19:15:02.920592","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
