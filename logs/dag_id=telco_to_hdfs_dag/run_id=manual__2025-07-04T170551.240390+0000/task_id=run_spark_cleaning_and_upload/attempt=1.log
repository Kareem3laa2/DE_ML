{"timestamp":"2025-07-04T17:05:57.036184","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-04T17:05:57.036671","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/telco_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-04T17:05:57.053677","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:57.054388","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec spark-master /opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 /opt/spark-apps/get_clean.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:57.062247","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.263840","level":"info","event":"25/07/04 17:05:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.954098","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.961852","level":"info","event":"25/07/04 17:05:58 INFO SparkContext: Running Spark version 3.1.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.997172","level":"info","event":"25/07/04 17:05:58 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.997382","level":"info","event":"25/07/04 17:05:58 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.997473","level":"info","event":"25/07/04 17:05:58 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:58.997788","level":"info","event":"25/07/04 17:05:58 INFO SparkContext: Submitted application: TelcoExploration","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.018184","level":"info","event":"25/07/04 17:05:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.027761","level":"info","event":"25/07/04 17:05:59 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.028215","level":"info","event":"25/07/04 17:05:59 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.070224","level":"info","event":"25/07/04 17:05:59 INFO SecurityManager: Changing view acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.070400","level":"info","event":"25/07/04 17:05:59 INFO SecurityManager: Changing modify acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.070453","level":"info","event":"25/07/04 17:05:59 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.070494","level":"info","event":"25/07/04 17:05:59 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.070533","level":"info","event":"25/07/04 17:05:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.281541","level":"info","event":"25/07/04 17:05:59 INFO Utils: Successfully started service 'sparkDriver' on port 43141.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.312849","level":"info","event":"25/07/04 17:05:59 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.343579","level":"info","event":"25/07/04 17:05:59 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.364996","level":"info","event":"25/07/04 17:05:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.366496","level":"info","event":"25/07/04 17:05:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.372871","level":"info","event":"25/07/04 17:05:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.386379","level":"info","event":"25/07/04 17:05:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-edb225e5-785f-4640-87cb-021c23b3a0ef","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.402556","level":"info","event":"25/07/04 17:05:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.416806","level":"info","event":"25/07/04 17:05:59 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.617622","level":"info","event":"25/07/04 17:05:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.662821","level":"info","event":"25/07/04 17:05:59 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://140fb6801c8d:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.677641","level":"info","event":"25/07/04 17:05:59 INFO SparkContext: Added JAR /opt/bitnami/spark/jars/postgresql-42.7.7.jar at spark://140fb6801c8d:43141/jars/postgresql-42.7.7.jar with timestamp 1751648758951","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.824094","level":"info","event":"25/07/04 17:05:59 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.876731","level":"info","event":"25/07/04 17:05:59 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.4:7077 after 32 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.952769","level":"info","event":"25/07/04 17:05:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250704170559-0009","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.961193","level":"info","event":"25/07/04 17:05:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42373.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.961375","level":"info","event":"25/07/04 17:05:59 INFO NettyBlockTransferService: Server created on 140fb6801c8d:42373","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.963164","level":"info","event":"25/07/04 17:05:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.973302","level":"info","event":"25/07/04 17:05:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 140fb6801c8d, 42373, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.976774","level":"info","event":"25/07/04 17:05:59 INFO BlockManagerMasterEndpoint: Registering block manager 140fb6801c8d:42373 with 366.3 MiB RAM, BlockManagerId(driver, 140fb6801c8d, 42373, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.978896","level":"info","event":"25/07/04 17:05:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 140fb6801c8d, 42373, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:05:59.980117","level":"info","event":"25/07/04 17:05:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 140fb6801c8d, 42373, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:00.164050","level":"info","event":"25/07/04 17:06:00 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:00.419868","level":"info","event":"25/07/04 17:06:00 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:00.420339","level":"info","event":"25/07/04 17:06:00 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:01.501641","level":"info","event":"25/07/04 17:06:01 INFO InMemoryFileIndex: It took 47 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:01.555840","level":"info","event":"25/07/04 17:06:01 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.185203","level":"info","event":"25/07/04 17:06:03 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.189300","level":"info","event":"25/07/04 17:06:03 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.192962","level":"info","event":"25/07/04 17:06:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.799045","level":"info","event":"25/07/04 17:06:03 INFO CodeGenerator: Code generated in 192.147632 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.915705","level":"info","event":"25/07/04 17:06:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 304.3 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.956327","level":"info","event":"25/07/04 17:06:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.959352","level":"info","event":"25/07/04 17:06:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 140fb6801c8d:42373 (size: 27.6 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.961734","level":"info","event":"25/07/04 17:06:03 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:03.968814","level":"info","event":"25/07/04 17:06:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.072570","level":"info","event":"25/07/04 17:06:04 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.086170","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.086333","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.086415","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.088058","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.091636","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.142352","level":"info","event":"25/07/04 17:06:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.145179","level":"info","event":"25/07/04 17:06:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.145523","level":"info","event":"25/07/04 17:06:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 140fb6801c8d:42373 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.146188","level":"info","event":"25/07/04 17:06:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.157907","level":"info","event":"25/07/04 17:06:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:04.158684","level":"info","event":"25/07/04 17:06:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:19.175253","level":"info","event":"25/07/04 17:06:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:34.176393","level":"info","event":"25/07/04 17:06:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:06:49.174989","level":"info","event":"25/07/04 17:06:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:07:04.176482","level":"info","event":"25/07/04 17:07:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:07:19.175240","level":"info","event":"25/07/04 17:07:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-04T17:07:34.174403","level":"info","event":"25/07/04 17:07:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
