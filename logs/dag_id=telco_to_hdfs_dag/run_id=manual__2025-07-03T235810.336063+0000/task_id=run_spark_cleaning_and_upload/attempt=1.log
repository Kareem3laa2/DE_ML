{"timestamp":"2025-07-03T23:58:14.628258","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-03T23:58:14.628761","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/telco_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-03T23:58:14.644349","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:14.644969","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec spark-master /opt/bitnami/spark/bin/spark-submit /opt/spark-apps/get_clean.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:14.653211","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:15.741509","level":"info","event":"25/07/03 23:58:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.364862","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.372163","level":"info","event":"25/07/03 23:58:16 INFO SparkContext: Running Spark version 3.1.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.401222","level":"info","event":"25/07/03 23:58:16 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.401411","level":"info","event":"25/07/03 23:58:16 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.401490","level":"info","event":"25/07/03 23:58:16 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.401914","level":"info","event":"25/07/03 23:58:16 INFO SparkContext: Submitted application: TelcoExploration","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.419196","level":"info","event":"25/07/03 23:58:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.428047","level":"info","event":"25/07/03 23:58:16 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.428710","level":"info","event":"25/07/03 23:58:16 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.467297","level":"info","event":"25/07/03 23:58:16 INFO SecurityManager: Changing view acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.467534","level":"info","event":"25/07/03 23:58:16 INFO SecurityManager: Changing modify acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.467701","level":"info","event":"25/07/03 23:58:16 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.467785","level":"info","event":"25/07/03 23:58:16 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.467845","level":"info","event":"25/07/03 23:58:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.653196","level":"info","event":"25/07/03 23:58:16 INFO Utils: Successfully started service 'sparkDriver' on port 35203.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.678105","level":"info","event":"25/07/03 23:58:16 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.703073","level":"info","event":"25/07/03 23:58:16 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.721606","level":"info","event":"25/07/03 23:58:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.722289","level":"info","event":"25/07/03 23:58:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.726889","level":"info","event":"25/07/03 23:58:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.737923","level":"info","event":"25/07/03 23:58:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-de7a33b6-ea34-4131-ab29-0ab36ac4b9d3","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.752565","level":"info","event":"25/07/03 23:58:16 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.766429","level":"info","event":"25/07/03 23:58:16 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.951794","level":"info","event":"25/07/03 23:58:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:16.994976","level":"info","event":"25/07/03 23:58:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ba2333d50e1e:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.149729","level":"info","event":"25/07/03 23:58:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.199142","level":"info","event":"25/07/03 23:58:17 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.2:7077 after 32 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.286695","level":"info","event":"25/07/03 23:58:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250703235817-0001","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.287826","level":"info","event":"25/07/03 23:58:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250703235817-0001/0 on worker-20250703235538-172.21.0.10-33271 (172.21.0.10:33271) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.289571","level":"info","event":"25/07/03 23:58:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20250703235817-0001/0 on hostPort 172.21.0.10:33271 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.295447","level":"info","event":"25/07/03 23:58:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40553.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.295661","level":"info","event":"25/07/03 23:58:17 INFO NettyBlockTransferService: Server created on ba2333d50e1e:40553","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.297635","level":"info","event":"25/07/03 23:58:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.307716","level":"info","event":"25/07/03 23:58:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ba2333d50e1e, 40553, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.311927","level":"info","event":"25/07/03 23:58:17 INFO BlockManagerMasterEndpoint: Registering block manager ba2333d50e1e:40553 with 366.3 MiB RAM, BlockManagerId(driver, ba2333d50e1e, 40553, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.314369","level":"info","event":"25/07/03 23:58:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ba2333d50e1e, 40553, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.315709","level":"info","event":"25/07/03 23:58:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ba2333d50e1e, 40553, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.320392","level":"info","event":"25/07/03 23:58:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250703235817-0001/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.520337","level":"info","event":"25/07/03 23:58:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.786015","level":"info","event":"25/07/03 23:58:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:17.786157","level":"info","event":"25/07/03 23:58:17 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:18.881090","level":"info","event":"25/07/03 23:58:18 INFO InMemoryFileIndex: It took 50 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:18.933292","level":"info","event":"25/07/03 23:58:18 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:19.040015","level":"info","event":"25/07/03 23:58:19 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.10:40276) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:19.126183","level":"info","event":"25/07/03 23:58:19 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.10:44265 with 366.3 MiB RAM, BlockManagerId(0, 172.21.0.10, 44265, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:20.534069","level":"info","event":"25/07/03 23:58:20 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:20.536815","level":"info","event":"25/07/03 23:58:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:20.542783","level":"info","event":"25/07/03 23:58:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.183075","level":"info","event":"25/07/03 23:58:21 INFO CodeGenerator: Code generated in 238.693338 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.233414","level":"info","event":"25/07/03 23:58:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 304.0 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.286870","level":"info","event":"25/07/03 23:58:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.289417","level":"info","event":"25/07/03 23:58:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ba2333d50e1e:40553 (size: 27.6 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.291351","level":"info","event":"25/07/03 23:58:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.298571","level":"info","event":"25/07/03 23:58:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.385157","level":"info","event":"25/07/03 23:58:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.398524","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.398745","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.398864","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.400230","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.404843","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.456928","level":"info","event":"25/07/03 23:58:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.459287","level":"info","event":"25/07/03 23:58:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.459741","level":"info","event":"25/07/03 23:58:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ba2333d50e1e:40553 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.460216","level":"info","event":"25/07/03 23:58:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.474132","level":"info","event":"25/07/03 23:58:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.476320","level":"info","event":"25/07/03 23:58:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.511370","level":"info","event":"25/07/03 23:58:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.10, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:21.698935","level":"info","event":"25/07/03 23:58:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.10:44265 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.435188","level":"info","event":"25/07/03 23:58:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.10:44265 (size: 27.6 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.972033","level":"info","event":"25/07/03 23:58:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1470 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.974278","level":"info","event":"25/07/03 23:58:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.979412","level":"info","event":"25/07/03 23:58:22 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.560 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.982357","level":"info","event":"25/07/03 23:58:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.982534","level":"info","event":"25/07/03 23:58:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:22.984367","level":"info","event":"25/07/03 23:58:22 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.599151 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.003270","level":"info","event":"25/07/03 23:58:23 INFO CodeGenerator: Code generated in 9.243446 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.046492","level":"info","event":"25/07/03 23:58:23 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.046639","level":"info","event":"25/07/03 23:58:23 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.046700","level":"info","event":"25/07/03 23:58:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.053354","level":"info","event":"25/07/03 23:58:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 304.0 KiB, free 365.7 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.059493","level":"info","event":"25/07/03 23:58:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.060077","level":"info","event":"25/07/03 23:58:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ba2333d50e1e:40553 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.061041","level":"info","event":"25/07/03 23:58:23 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.061809","level":"info","event":"25/07/03 23:58:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.107192","level":"info","event":"25/07/03 23:58:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.108452","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.108776","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.108875","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.108915","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.109841","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.127841","level":"info","event":"25/07/03 23:58:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.129495","level":"info","event":"25/07/03 23:58:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.129637","level":"info","event":"25/07/03 23:58:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ba2333d50e1e:40553 (size: 8.1 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.130269","level":"info","event":"25/07/03 23:58:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.131065","level":"info","event":"25/07/03 23:58:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.131365","level":"info","event":"25/07/03 23:58:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.133434","level":"info","event":"25/07/03 23:58:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.10, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:23.153130","level":"info","event":"25/07/03 23:58:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.10:44265 (size: 8.1 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.158342","level":"info","event":"25/07/03 23:58:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.10:44265 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.351779","level":"info","event":"25/07/03 23:58:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1219 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.351960","level":"info","event":"25/07/03 23:58:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.352477","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 1.241 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.352583","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.352641","level":"info","event":"25/07/03 23:58:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.354542","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 1.247247 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.813125","level":"info","event":"25/07/03 23:58:24 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.813294","level":"info","event":"25/07/03 23:58:24 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.813679","level":"info","event":"25/07/03 23:58:24 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.849299","level":"info","event":"25/07/03 23:58:24 INFO CodeGenerator: Code generated in 15.326894 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.853916","level":"info","event":"25/07/03 23:58:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 303.9 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.860982","level":"info","event":"25/07/03 23:58:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.862149","level":"info","event":"25/07/03 23:58:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ba2333d50e1e:40553 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.862589","level":"info","event":"25/07/03 23:58:24 INFO SparkContext: Created broadcast 4 from approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.865519","level":"info","event":"25/07/03 23:58:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.885743","level":"info","event":"25/07/03 23:58:24 INFO SparkContext: Starting job: approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.886613","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Got job 2 (approxQuantile at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.886722","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Final stage: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.886784","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.886830","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.888062","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.901284","level":"info","event":"25/07/03 23:58:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 20.2 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.902766","level":"info","event":"25/07/03 23:58:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.903989","level":"info","event":"25/07/03 23:58:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ba2333d50e1e:40553 (size: 9.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.904229","level":"info","event":"25/07/03 23:58:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.904709","level":"info","event":"25/07/03 23:58:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.904795","level":"info","event":"25/07/03 23:58:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.906636","level":"info","event":"25/07/03 23:58:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.10, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.918137","level":"info","event":"25/07/03 23:58:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.10:44265 (size: 9.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:24.997110","level":"info","event":"25/07/03 23:58:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.10:44265 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.119825","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 213 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.119997","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.120396","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0) finished in 0.232 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.120704","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.120796","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.122600","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Job 2 finished: approxQuantile at NativeMethodAccessorImpl.java:0, took 0.236427 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.221782","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.223216","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Post-Scan Filters: ((CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END < -3927.1499999999996) OR (CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END > 7662.049999999999))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.223488","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.277054","level":"info","event":"25/07/03 23:58:25 INFO CodeGenerator: Code generated in 11.652177 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.315814","level":"info","event":"25/07/03 23:58:25 INFO CodeGenerator: Code generated in 27.063336 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.319327","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 303.9 KiB, free 365.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.329902","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.330324","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ba2333d50e1e:40553 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.331175","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.331936","level":"info","event":"25/07/03 23:58:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.365669","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.368015","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.369900","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.370005","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.370046","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.371085","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.372651","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.382334","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 19.7 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.386594","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.387852","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ba2333d50e1e:40553 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.387991","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.389923","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.390054","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.392423","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.10, executor 0, partition 0, ANY, 4865 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.406415","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.10:44265 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.473857","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.10:44265 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.540420","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 150 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.540612","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.542868","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.166 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.543005","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.543077","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.543380","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: waiting: Set(ResultStage 4)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.543817","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.546190","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.552722","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.558000","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.559001","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ba2333d50e1e:40553 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.563169","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.563360","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.563436","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.567498","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.21.0.10, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.582161","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.10:44265 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.595704","level":"info","event":"25/07/03 23:58:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.10:40276","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.671107","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 108 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.671331","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.672204","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.121 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.672344","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.672413","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.672571","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.306521 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.676591","level":"info","event":"Number of outliers in totalcharges: 154","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.761822","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ba2333d50e1e:40553 in memory (size: 9.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.766357","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.21.0.10:44265 in memory (size: 9.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.775169","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ba2333d50e1e:40553 in memory (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.776529","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.21.0.10:44265 in memory (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.783540","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ba2333d50e1e:40553 in memory (size: 5.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.785245","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.21.0.10:44265 in memory (size: 5.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.793019","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ba2333d50e1e:40553 in memory (size: 8.1 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.793760","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.21.0.10:44265 in memory (size: 8.1 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.801489","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ba2333d50e1e:40553 in memory (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.801697","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.802221","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.802875","level":"info","event":"25/07/03 23:58:25 INFO FileSourceStrategy: Output Data Schema: struct<customerID: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string ... 19 more fields>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.803417","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.21.0.10:44265 in memory (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.811196","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ba2333d50e1e:40553 in memory (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.813629","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.10:44265 in memory (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.854538","level":"info","event":"25/07/03 23:58:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.870420","level":"info","event":"25/07/03 23:58:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.870605","level":"info","event":"25/07/03 23:58:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.870979","level":"info","event":"25/07/03 23:58:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.871117","level":"info","event":"25/07/03 23:58:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.871190","level":"info","event":"25/07/03 23:58:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.872178","level":"info","event":"25/07/03 23:58:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.926731","level":"info","event":"25/07/03 23:58:25 INFO CodeGenerator: Code generated in 28.601358 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.930391","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 303.9 KiB, free 365.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.936298","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 365.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.936864","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ba2333d50e1e:40553 (size: 27.6 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.937318","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Created broadcast 9 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.938561","level":"info","event":"25/07/03 23:58:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.961070","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.961997","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Got job 4 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.962108","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.962167","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.962215","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.963152","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.974516","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 191.3 KiB, free 364.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.976584","level":"info","event":"25/07/03 23:58:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 66.9 KiB, free 364.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.977823","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ba2333d50e1e:40553 (size: 66.9 KiB, free: 366.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.977964","level":"info","event":"25/07/03 23:58:25 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.978416","level":"info","event":"25/07/03 23:58:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.978522","level":"info","event":"25/07/03 23:58:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.980325","level":"info","event":"25/07/03 23:58:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.21.0.10, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:25.992214","level":"info","event":"25/07/03 23:58:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.21.0.10:44265 (size: 66.9 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.408937","level":"info","event":"25/07/03 23:58:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.21.0.10:44265 (size: 27.6 KiB, free: 366.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.854965","level":"info","event":"25/07/03 23:58:26 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 875 ms on 172.21.0.10 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.855289","level":"info","event":"25/07/03 23:58:26 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.855746","level":"info","event":"25/07/03 23:58:26 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.891 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.856260","level":"info","event":"25/07/03 23:58:26 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.856386","level":"info","event":"25/07/03 23:58:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.858070","level":"info","event":"25/07/03 23:58:26 INFO DAGScheduler: Job 4 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.896597 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.919494","level":"info","event":"25/07/03 23:58:26 INFO FileFormatWriter: Write Job 846e7cce-7391-4922-8b1f-a6aedb603e0f committed.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.923427","level":"info","event":"25/07/03 23:58:26 INFO FileFormatWriter: Finished processing stats for write job 846e7cce-7391-4922-8b1f-a6aedb603e0f.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.962005","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.962129","level":"info","event":"  File \"/opt/spark-apps/get_clean.py\", line 68, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.963688","level":"info","event":"    .mode(\"overwrite\")\\","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.963820","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1107, in save","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.964083","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.964727","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 111, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.964849","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966116","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o116.save.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966193","level":"info","event":": java.lang.ClassNotFoundException: org.postgresql.Driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966227","level":"info","event":"\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966253","level":"info","event":"\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966277","level":"info","event":"\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966300","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966324","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966347","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966369","level":"info","event":"\tat scala.Option.foreach(Option.scala:407)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966391","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966414","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:215)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966436","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:219)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966458","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966480","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966501","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966523","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966543","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966564","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966585","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966606","level":"info","event":"\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966628","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966649","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966669","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966689","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966710","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966736","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966760","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966783","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966807","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966828","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966849","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966869","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966888","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966909","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966930","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966952","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966973","level":"info","event":"\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.966994","level":"info","event":"\tat java.lang.reflect.Method.invoke(Method.java:498)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967015","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967036","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967060","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967080","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967101","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967123","level":"info","event":"\tat py4j.GatewayConnection.run(GatewayConnection.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967144","level":"info","event":"\tat java.lang.Thread.run(Thread.java:748)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.967166","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:26.996222","level":"info","event":"25/07/03 23:58:26 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.005343","level":"info","event":"25/07/03 23:58:27 INFO SparkUI: Stopped Spark web UI at http://ba2333d50e1e:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.007935","level":"info","event":"25/07/03 23:58:27 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.008095","level":"info","event":"25/07/03 23:58:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.022437","level":"info","event":"25/07/03 23:58:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.036024","level":"info","event":"25/07/03 23:58:27 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.036577","level":"info","event":"25/07/03 23:58:27 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.042035","level":"info","event":"25/07/03 23:58:27 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.044317","level":"info","event":"25/07/03 23:58:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.051202","level":"info","event":"25/07/03 23:58:27 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.051693","level":"info","event":"25/07/03 23:58:27 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.051774","level":"info","event":"25/07/03 23:58:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-16d6e435-d2fe-4626-9852-3444c077943b","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.055189","level":"info","event":"25/07/03 23:58:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc508436-807c-4717-88ab-ba8d5904feda/pyspark-e60a09dd-9ac9-4564-9cc7-dbdcceffc427","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.059040","level":"info","event":"25/07/03 23:58:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc508436-807c-4717-88ab-ba8d5904feda","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.199999","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:58:27.200501","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
