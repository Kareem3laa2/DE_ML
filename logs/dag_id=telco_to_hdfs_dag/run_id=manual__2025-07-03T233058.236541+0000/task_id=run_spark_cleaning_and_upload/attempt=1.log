{"timestamp":"2025-07-03T23:31:03.126711","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-03T23:31:03.127429","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/telco_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-03T23:31:03.146984","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:03.148452","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec spark-master /opt/bitnami/spark/bin/spark-submit /opt/spark-apps/get_clean.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:03.161814","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:04.620271","level":"info","event":"25/07/03 23:31:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.393056","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.402113","level":"info","event":"25/07/03 23:31:05 INFO SparkContext: Running Spark version 3.1.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.439128","level":"info","event":"25/07/03 23:31:05 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.439424","level":"info","event":"25/07/03 23:31:05 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.439558","level":"info","event":"25/07/03 23:31:05 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.440215","level":"info","event":"25/07/03 23:31:05 INFO SparkContext: Submitted application: TelcoExploration","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.465041","level":"info","event":"25/07/03 23:31:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.475031","level":"info","event":"25/07/03 23:31:05 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.475510","level":"info","event":"25/07/03 23:31:05 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.523422","level":"info","event":"25/07/03 23:31:05 INFO SecurityManager: Changing view acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.523558","level":"info","event":"25/07/03 23:31:05 INFO SecurityManager: Changing modify acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.523601","level":"info","event":"25/07/03 23:31:05 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.523631","level":"info","event":"25/07/03 23:31:05 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.523657","level":"info","event":"25/07/03 23:31:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.711176","level":"info","event":"25/07/03 23:31:05 INFO Utils: Successfully started service 'sparkDriver' on port 40701.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.736998","level":"info","event":"25/07/03 23:31:05 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.766755","level":"info","event":"25/07/03 23:31:05 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.786228","level":"info","event":"25/07/03 23:31:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.786404","level":"info","event":"25/07/03 23:31:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.791062","level":"info","event":"25/07/03 23:31:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.805962","level":"info","event":"25/07/03 23:31:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9c4b0973-b81d-4089-a3c3-6b625dd3a40f","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.824329","level":"info","event":"25/07/03 23:31:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:05.844232","level":"info","event":"25/07/03 23:31:05 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.085142","level":"info","event":"25/07/03 23:31:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.143525","level":"info","event":"25/07/03 23:31:06 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://bdbce0b0eeea:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.342276","level":"info","event":"25/07/03 23:31:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.394319","level":"info","event":"25/07/03 23:31:06 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.4:7077 after 32 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.527985","level":"info","event":"25/07/03 23:31:06 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250703233106-0000","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.536399","level":"info","event":"25/07/03 23:31:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35675.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.536571","level":"info","event":"25/07/03 23:31:06 INFO NettyBlockTransferService: Server created on bdbce0b0eeea:35675","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.539291","level":"info","event":"25/07/03 23:31:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.549988","level":"info","event":"25/07/03 23:31:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, bdbce0b0eeea, 35675, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.558229","level":"info","event":"25/07/03 23:31:06 INFO BlockManagerMasterEndpoint: Registering block manager bdbce0b0eeea:35675 with 366.3 MiB RAM, BlockManagerId(driver, bdbce0b0eeea, 35675, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.564363","level":"info","event":"25/07/03 23:31:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, bdbce0b0eeea, 35675, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.572887","level":"info","event":"25/07/03 23:31:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, bdbce0b0eeea, 35675, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.582608","level":"info","event":"25/07/03 23:31:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250703233106-0000/0 on worker-20250703232811-172.21.0.6-43319 (172.21.0.6:43319) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.582780","level":"info","event":"25/07/03 23:31:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250703233106-0000/0 on hostPort 172.21.0.6:43319 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.816941","level":"info","event":"25/07/03 23:31:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250703233106-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:06.915438","level":"info","event":"25/07/03 23:31:06 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:07.192938","level":"info","event":"25/07/03 23:31:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:07.193134","level":"info","event":"25/07/03 23:31:07 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:08.533454","level":"info","event":"25/07/03 23:31:08 INFO InMemoryFileIndex: It took 67 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:08.611552","level":"info","event":"25/07/03 23:31:08 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:08.949681","level":"info","event":"25/07/03 23:31:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.6:54366) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:09.135796","level":"info","event":"25/07/03 23:31:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.6:44695 with 366.3 MiB RAM, BlockManagerId(0, 172.21.0.6, 44695, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:10.877065","level":"info","event":"25/07/03 23:31:10 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:10.881242","level":"info","event":"25/07/03 23:31:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:10.884437","level":"info","event":"25/07/03 23:31:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.584058","level":"info","event":"25/07/03 23:31:11 INFO CodeGenerator: Code generated in 263.491099 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.640182","level":"info","event":"25/07/03 23:31:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 303.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.688453","level":"info","event":"25/07/03 23:31:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.691857","level":"info","event":"25/07/03 23:31:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on bdbce0b0eeea:35675 (size: 27.5 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.695489","level":"info","event":"25/07/03 23:31:11 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.703761","level":"info","event":"25/07/03 23:31:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.810873","level":"info","event":"25/07/03 23:31:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.825237","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.825396","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.825446","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.826552","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.832087","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.886552","level":"info","event":"25/07/03 23:31:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.890175","level":"info","event":"25/07/03 23:31:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.890348","level":"info","event":"25/07/03 23:31:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on bdbce0b0eeea:35675 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.890881","level":"info","event":"25/07/03 23:31:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.904269","level":"info","event":"25/07/03 23:31:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.904728","level":"info","event":"25/07/03 23:31:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:11.940998","level":"info","event":"25/07/03 23:31:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:12.135469","level":"info","event":"25/07/03 23:31:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.6:44695 (size: 5.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:12.928477","level":"info","event":"25/07/03 23:31:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.6:44695 (size: 27.5 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.636431","level":"info","event":"25/07/03 23:31:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1705 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.640411","level":"info","event":"25/07/03 23:31:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.649948","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.803 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.654005","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.654167","level":"info","event":"25/07/03 23:31:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.659071","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.847363 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.693924","level":"info","event":"25/07/03 23:31:13 INFO CodeGenerator: Code generated in 19.188578 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.765590","level":"info","event":"25/07/03 23:31:13 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.765790","level":"info","event":"25/07/03 23:31:13 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.765852","level":"info","event":"25/07/03 23:31:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.773535","level":"info","event":"25/07/03 23:31:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 303.8 KiB, free 365.7 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.784097","level":"info","event":"25/07/03 23:31:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.784916","level":"info","event":"25/07/03 23:31:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on bdbce0b0eeea:35675 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.786046","level":"info","event":"25/07/03 23:31:13 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.786712","level":"info","event":"25/07/03 23:31:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.856946","level":"info","event":"25/07/03 23:31:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.858841","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.859043","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.859123","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.859173","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.863083","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.889539","level":"info","event":"25/07/03 23:31:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.8 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.891669","level":"info","event":"25/07/03 23:31:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 365.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.892132","level":"info","event":"25/07/03 23:31:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on bdbce0b0eeea:35675 (size: 8.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.892258","level":"info","event":"25/07/03 23:31:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.892972","level":"info","event":"25/07/03 23:31:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.893097","level":"info","event":"25/07/03 23:31:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.895529","level":"info","event":"25/07/03 23:31:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:13.919827","level":"info","event":"25/07/03 23:31:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.6:44695 (size: 8.0 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.141713","level":"info","event":"25/07/03 23:31:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.6:44695 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.315785","level":"info","event":"25/07/03 23:31:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1421 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.316000","level":"info","event":"25/07/03 23:31:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.316796","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 1.455 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.316921","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.316980","level":"info","event":"25/07/03 23:31:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.318677","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 1.461750 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.836086","level":"info","event":"25/07/03 23:31:15 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.836234","level":"info","event":"25/07/03 23:31:15 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.836279","level":"info","event":"25/07/03 23:31:15 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.880134","level":"info","event":"25/07/03 23:31:15 INFO CodeGenerator: Code generated in 17.851113 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.885575","level":"info","event":"25/07/03 23:31:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 303.7 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.895544","level":"info","event":"25/07/03 23:31:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.896388","level":"info","event":"25/07/03 23:31:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on bdbce0b0eeea:35675 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.897360","level":"info","event":"25/07/03 23:31:15 INFO SparkContext: Created broadcast 4 from approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.901409","level":"info","event":"25/07/03 23:31:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.931733","level":"info","event":"25/07/03 23:31:15 INFO SparkContext: Starting job: approxQuantile at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.932655","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Got job 2 (approxQuantile at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.932805","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Final stage: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.932878","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.934367","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.934543","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.951537","level":"info","event":"25/07/03 23:31:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 20.1 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.953734","level":"info","event":"25/07/03 23:31:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.954818","level":"info","event":"25/07/03 23:31:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on bdbce0b0eeea:35675 (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.955220","level":"info","event":"25/07/03 23:31:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.955691","level":"info","event":"25/07/03 23:31:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at approxQuantile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.955784","level":"info","event":"25/07/03 23:31:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.957504","level":"info","event":"25/07/03 23:31:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:15.974869","level":"info","event":"25/07/03 23:31:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.6:44695 (size: 9.7 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.085387","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.6:44695 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.251463","level":"info","event":"25/07/03 23:31:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 293 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.251649","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.252661","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: ResultStage 2 (approxQuantile at NativeMethodAccessorImpl.java:0) finished in 0.317 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.252818","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.252922","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.255372","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Job 2 finished: approxQuantile at NativeMethodAccessorImpl.java:0, took 0.323058 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.370182","level":"info","event":"25/07/03 23:31:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.370889","level":"info","event":"25/07/03 23:31:16 INFO FileSourceStrategy: Post-Scan Filters: ((CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END < -3927.1499999999996) OR (CASE WHEN isnull(cast(TotalCharges#35 as double)) THEN 0.0 ELSE cast(TotalCharges#35 as double) END > 7662.049999999999))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.371287","level":"info","event":"25/07/03 23:31:16 INFO FileSourceStrategy: Output Data Schema: struct<TotalCharges: string>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.416182","level":"info","event":"25/07/03 23:31:16 INFO CodeGenerator: Code generated in 10.307221 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.448404","level":"info","event":"25/07/03 23:31:16 INFO CodeGenerator: Code generated in 22.391378 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.452936","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 303.7 KiB, free 365.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.461440","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.462251","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on bdbce0b0eeea:35675 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.462772","level":"info","event":"25/07/03 23:31:16 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.463877","level":"info","event":"25/07/03 23:31:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.499452","level":"info","event":"25/07/03 23:31:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.502228","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.504327","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.504536","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.504610","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.505837","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.507165","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.517575","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 19.7 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.520110","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.520873","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on bdbce0b0eeea:35675 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.521042","level":"info","event":"25/07/03 23:31:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.523227","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.523383","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.525816","level":"info","event":"25/07/03 23:31:16 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.6, executor 0, partition 0, ANY, 4865 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.542992","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.6:44695 (size: 9.3 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.643556","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.6:44695 (size: 27.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.743192","level":"info","event":"25/07/03 23:31:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 218 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.743405","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.744581","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.233 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.744720","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.745032","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.745429","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: waiting: Set(ResultStage 4)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.745758","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.748632","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.755567","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.757093","level":"info","event":"25/07/03 23:31:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.758320","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on bdbce0b0eeea:35675 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.759134","level":"info","event":"25/07/03 23:31:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.760977","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.761214","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.766380","level":"info","event":"25/07/03 23:31:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.21.0.6, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.787340","level":"info","event":"25/07/03 23:31:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.6:44695 (size: 5.0 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.805770","level":"info","event":"25/07/03 23:31:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.6:54366","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.894403","level":"info","event":"25/07/03 23:31:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 131 ms on 172.21.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.894607","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.895278","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.140 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.895400","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.895493","level":"info","event":"25/07/03 23:31:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.895879","level":"info","event":"25/07/03 23:31:16 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.396561 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:16.899235","level":"info","event":"Number of outliers in totalcharges: 154","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.003784","level":"info","event":"25/07/03 23:31:17 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.004006","level":"info","event":"25/07/03 23:31:17 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.004091","level":"info","event":"25/07/03 23:31:17 INFO FileSourceStrategy: Output Data Schema: struct<customerID: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string ... 19 more fields>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.092842","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.093141","level":"info","event":"  File \"/opt/spark-apps/get_clean.py\", line 50, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.097042","level":"info","event":"    df_cleaned.write.mode(\"overwrite\").parquet(\"hdfs://namenode:8020/user/telco/cleaned/telco_cleaned.parquet\")","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.097308","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1249, in parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.098284","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.099410","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 111, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.100052","level":"info","event":"  File \"/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.146933","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o104.parquet.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147290","level":"info","event":": org.apache.hadoop.security.AccessControlException: Permission denied: user=spark, access=WRITE, inode=\"/user/telco/cleaned\":root:supergroup:drwxr-xr-x","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147485","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:399)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147622","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:258)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147728","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147814","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1879)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.147896","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:110)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148140","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3085)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148308","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148477","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148594","level":"info","event":"\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148690","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148778","level":"info","event":"\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148867","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.148958","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149046","level":"info","event":"\tat java.security.AccessController.doPrivileged(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149133","level":"info","event":"\tat javax.security.auth.Subject.doAs(Subject.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149220","level":"info","event":"\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149304","level":"info","event":"\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149392","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149482","level":"info","event":"\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149565","level":"info","event":"\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149651","level":"info","event":"\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149736","level":"info","event":"\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149817","level":"info","event":"\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149900","level":"info","event":"\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.149976","level":"info","event":"\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150031","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150075","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150114","level":"info","event":"\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150153","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150192","level":"info","event":"\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150233","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:236)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150274","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:130)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150314","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150356","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150443","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150510","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150562","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150610","level":"info","event":"\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150676","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150747","level":"info","event":"\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150822","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150888","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.150951","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151042","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151115","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151182","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151251","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151321","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151387","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151604","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.151880","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152059","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152168","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152266","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152435","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152558","level":"info","event":"\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152654","level":"info","event":"\tat java.lang.reflect.Method.invoke(Method.java:498)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152746","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152839","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.152929","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153017","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153159","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153274","level":"info","event":"\tat py4j.GatewayConnection.run(GatewayConnection.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153370","level":"info","event":"\tat java.lang.Thread.run(Thread.java:748)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153470","level":"info","event":"Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=spark, access=WRITE, inode=\"/user/telco/cleaned\":root:supergroup:drwxr-xr-x","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153570","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:399)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153634","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:258)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153703","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153772","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1879)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153844","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:110)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153911","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3085)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.153970","level":"info","event":"\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154038","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154112","level":"info","event":"\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154191","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154256","level":"info","event":"\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154313","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154386","level":"info","event":"\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154455","level":"info","event":"\tat java.security.AccessController.doPrivileged(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154500","level":"info","event":"\tat javax.security.auth.Subject.doAs(Subject.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154637","level":"info","event":"\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.154886","level":"info","event":"\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155141","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155278","level":"info","event":"\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155481","level":"info","event":"\tat org.apache.hadoop.ipc.Client.call(Client.java:1457)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155688","level":"info","event":"\tat org.apache.hadoop.ipc.Client.call(Client.java:1367)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155826","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.155897","level":"info","event":"\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.156275","level":"info","event":"\tat com.sun.proxy.$Proxy19.delete(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.156669","level":"info","event":"\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.156916","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157264","level":"info","event":"\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157473","level":"info","event":"\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157576","level":"info","event":"\tat java.lang.reflect.Method.invoke(Method.java:498)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157680","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157732","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157782","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157898","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.157953","level":"info","event":"\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.158078","level":"info","event":"\tat com.sun.proxy.$Proxy20.delete(Unknown Source)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.158139","level":"info","event":"\tat org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.158183","level":"info","event":"\t... 39 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.158374","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.191220","level":"info","event":"25/07/03 23:31:17 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.200869","level":"info","event":"25/07/03 23:31:17 INFO SparkUI: Stopped Spark web UI at http://bdbce0b0eeea:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.204195","level":"info","event":"25/07/03 23:31:17 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.204401","level":"info","event":"25/07/03 23:31:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.232570","level":"info","event":"25/07/03 23:31:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.254102","level":"info","event":"25/07/03 23:31:17 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.254241","level":"info","event":"25/07/03 23:31:17 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.265217","level":"info","event":"25/07/03 23:31:17 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.269001","level":"info","event":"25/07/03 23:31:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.276676","level":"info","event":"25/07/03 23:31:17 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.277062","level":"info","event":"25/07/03 23:31:17 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.277188","level":"info","event":"25/07/03 23:31:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-a7e9b4cc-a4ff-4c74-bb3b-358e7027e27e","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.280866","level":"info","event":"25/07/03 23:31:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-f75be3cc-a57b-4dd9-9707-7e10c1accba6","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.284308","level":"info","event":"25/07/03 23:31:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-f75be3cc-a57b-4dd9-9707-7e10c1accba6/pyspark-9ec6d83b-a57c-4397-b4e0-0730aeed3bd4","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.436848","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-03T23:31:17.437337","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
